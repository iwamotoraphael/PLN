{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EP1\n",
    "## Classificação da clareza das respostas na plataforma eSIC\n",
    "\n",
    "ACH2118 - Introdução ao Processamento de Língua Natural\n",
    "\n",
    "Professor Ivandré Paraboni\n",
    "\n",
    "Integrantes:\n",
    "* Luiza Borghi de Mello - 11796037\n",
    "* Raphael Nobuaki Iwamoto - 11882986\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install spacy\n",
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "\n",
    "!python -m spacy download pt_core_news_lg\n",
    "!python3 -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "import time\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "def aplica_lematizacao(df: pd.DataFrame, coluna: str):\n",
    "    df[coluna + '_lematizada'] = ''\n",
    "    i = 0\n",
    "    for text in df[coluna]:\n",
    "        doc = nlp(text)\n",
    "        lemma = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
    "        df[coluna + '_lematizada'].iloc[i] = \" \".join(x for x in lemma)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('rslp')\n",
    "\n",
    "def aplica_stemming(df: pd.DataFrame, coluna: str):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    df[coluna + '_stemming'] = df[coluna].apply(lambda x: \" \".join(stemmer.stem(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(df: pd.DataFrame, coluna: str):\n",
    "    stop = nltk.corpus.stopwords.words('portuguese')\n",
    "    df[coluna + '_stopwords'] = df[coluna].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e análise do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_dataset = pd.read_excel('data/ep1_esic2023_clareza_TRAIN.xlsx')\n",
    "treino_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = treino_dataset['clarity'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplica_lematizacao(treino_dataset, 'resp_text')\n",
    "aplica_stemming(treino_dataset, 'resp_text')\n",
    "remove_stopwords(treino_dataset, 'resp_text')\n",
    "\n",
    "treino_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression | sem pré-processamento | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "lowercase_list = [True, False]\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n",
    "C_list = [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "class_weight_list = ['balanced', None]\n",
    "penalty_list = ['l1', 'l2']\n",
    "solver_list = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for lowercase, analyzer, ngram_range, C, class_weight, penalty, solver in itertools.product(lowercase_list, analyzer_list, ngram_range_list, C_list, class_weight_list, penalty_list, solver_list):\n",
    "    vectorizer = CountVectorizer(analyzer=analyzer, lowercase=lowercase, ngram_range=ngram_range)\n",
    "    X_count = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=9999, C=C, class_weight=class_weight, penalty=penalty, solver=solver, random_state=100)\n",
    "\n",
    "    accuracy = 0\n",
    "    try:\n",
    "        accuracy = cross_val_score(clf, X_count, Y, scoring='accuracy', cv=10, error_score='raise').mean()\n",
    "\n",
    "        print(f\"Hyperparameters: lowercase={lowercase}, analyzer={analyzer}, ngram_range={ngram_range}, C={C}, class_weight={class_weight}, penalty={penalty}, solver={solver}\")\n",
    "        print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = {\n",
    "                'lowercase': lowercase,\n",
    "                'analyzer': analyzer,\n",
    "                'ngram_range': ngram_range,\n",
    "                'C': C,\n",
    "                'class_weight': class_weight,\n",
    "                'penalty': penalty,\n",
    "                'solver': solver\n",
    "            }\n",
    "    except:\n",
    "        print('Combination skipped\\n')\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "lowercase_list = [True, False]\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(2, 2), (3, 3), (4, 4), (5, 5)]\n",
    "C_list = np.geomspace(3.0, 5.0, num=20)\n",
    "class_weight_list = ['balanced', None]\n",
    "penalty_list = ['l1', 'l2']\n",
    "solver_list = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for lowercase, analyzer, ngram_range, C, class_weight, penalty, solver in itertools.product(lowercase_list, analyzer_list, ngram_range_list, C_list, class_weight_list, penalty_list, solver_list):\n",
    "    vectorizer = TfidfVectorizer(analyzer=analyzer, lowercase=lowercase, ngram_range=ngram_range)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = TfidfVectorizer(max_iter=9999, C=C, class_weight=class_weight, penalty=penalty, solver=solver, random_state=100)\n",
    "\n",
    "    accuracy = 0\n",
    "    try:\n",
    "        accuracy = cross_val_score(clf, X_tfidf, Y, scoring='accuracy', cv=10, error_score='raise').mean()\n",
    "\n",
    "        print(f\"Hyperparameters: lowercase={lowercase}, analyzer={analyzer}, ngram_range={ngram_range}, C={C}, class_weight={class_weight}, penalty={penalty}, solver={solver}\")\n",
    "        print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = {\n",
    "                'lowercase': lowercase,\n",
    "                'analyzer': analyzer,\n",
    "                'ngram_range': ngram_range,\n",
    "                'C': C,\n",
    "                'class_weight': class_weight,\n",
    "                'penalty': penalty,\n",
    "                'solver': solver\n",
    "            }\n",
    "    except:\n",
    "        print('Combination skipped\\n')\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Naive Bayes | sem pré-processamento | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2), (3, 3), (5, 5)]\n",
    "alpha_list = np.geomspace(1e-3, 1, num=50)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for analyzer, ngram_range, alpha in itertools.product(analyzer_list, ngram_range_list, alpha_list):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "    X_count = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    accuracy = cross_val_score(clf, X_count, Y, scoring='accuracy', cv=10).mean()\n",
    "\n",
    "    print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}, alpha={alpha}\")\n",
    "    print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {\n",
    "            'ngram_range': ngram_range,\n",
    "            'analyzer': analyzer,\n",
    "            'alpha': alpha\n",
    "        }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Naive Bayes | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2), (3, 3), (5, 5)]\n",
    "alpha_list = np.geomspace(1e-3, 1000, num=100)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for analyzer, ngram_range, alpha in itertools.product(analyzer_list, ngram_range_list, alpha_list):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    accuracy = cross_val_score(clf, X_tfidf, Y, scoring='accuracy', cv=10).mean()\n",
    "\n",
    "    print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}, alpha={alpha}\")\n",
    "    print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {\n",
    "            'ngram_range': ngram_range,\n",
    "            'analyzer': analyzer,\n",
    "            'alpha': alpha\n",
    "        }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Random Forest | Lematização | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer = 'word'\n",
    "ngram_range = (1, 1)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "X_count = vectorizer.fit_transform(X)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=100)\n",
    "\n",
    "accuracy = cross_val_score(clf, X, Y, scoring='accuracy', cv=10, n_jobs=3).mean()\n",
    "\n",
    "print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}\")\n",
    "print(f\"Mean Accuracy: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Random Forest | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2)]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for analyzer, ngram_range in itertools.product(analyzer_list, ngram_range_list):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=100)\n",
    "\n",
    "    accuracy = cross_val_score(clf, X, Y, scoring='accuracy', cv=10).mean()\n",
    "\n",
    "    print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}\")\n",
    "    print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {\n",
    "            'ngram_range': ngram_range,\n",
    "            'analyzer': analyzer,\n",
    "        }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. SVC | Lematização | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. SVC | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. SGD Classifier | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
