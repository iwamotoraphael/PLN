{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EP1\n",
    "## Classificação da clareza das respostas na plataforma eSIC\n",
    "\n",
    "ACH2118 - Introdução ao Processamento de Língua Natural\n",
    "\n",
    "Professor Ivandré Paraboni\n",
    "\n",
    "Integrantes:\n",
    "* Luiza Borghi de Mello - 11796037\n",
    "* Raphael Nobuaki Iwamoto - 11882986\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\raphael\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raphael\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Raphael\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Raphael\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.26.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raphael\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\raphael\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Raphael\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\raphael\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Raphael\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Raphael\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Raphael\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Collecting pt-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.7.0/pt_core_news_lg-3.7.0-py3-none-any.whl (568.2 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pt-core-news-lg==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (58.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raphael\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\raphael\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raphael\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Raphael\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n",
      "Python n�o encontrado; execute sem argumentos para instalar na Microsoft Store ou desabilite este atalho a partir de Configura��es > Gerenciar Aliases de Execu��o do Aplicativo.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install spacy\n",
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "%pip install openpyxl\n",
    "\n",
    "!python -m spacy download pt_core_news_lg\n",
    "!python3 -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "import time\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_classif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "def aplica_lematizacao(df: pd.DataFrame, coluna: str):\n",
    "    df[coluna + '_lematizada'] = ''\n",
    "    i = 0\n",
    "    for text in df[coluna]:\n",
    "        doc = nlp(text)\n",
    "        lemma = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
    "        df[coluna + '_lematizada'].iloc[i] = \" \".join(x for x in lemma)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Raphael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('rslp')\n",
    "\n",
    "def aplica_stemming(df: pd.DataFrame, coluna: str):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    df[coluna + '_stemming'] = df[coluna].apply(lambda x: \" \".join(stemmer.stem(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Raphael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(df: pd.DataFrame, coluna: str):\n",
    "    stop = nltk.corpus.stopwords.words('portuguese')\n",
    "    df[coluna + '_stopwords'] = df[coluna].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e análise do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prezado Sr Jose Taunai  Em atenção ao seu pe...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A pedido do Pró-Reitor de Graduação, informa...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos o contato e...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos o contato e...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Prezado Prof. Gilberto Tadeu Reis da Silva  ...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>Trata-se de solicitação com base na Lei de Ac...</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Trata-se de uma solicitação repetida. As info...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Unidade:</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Vale dizer que a gestão dos Telefones de Uso ...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>WILHAN DONIZETE GONçALVES NUNES, neste NUP 23...</td>\n",
       "      <td>c234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resp_text clarity\n",
       "0       Prezado Sr Jose Taunai  Em atenção ao seu pe...      c5\n",
       "1      \"A pedido do Pró-Reitor de Graduação, informa...      c5\n",
       "2      \"Prezado (a) Sr. (a), Agradecemos o contato e...    c234\n",
       "3      \"Prezado (a) Sr. (a), Agradecemos o contato e...    c234\n",
       "4      \"Prezado Prof. Gilberto Tadeu Reis da Silva  ...    c234\n",
       "...                                                 ...     ...\n",
       "5995   Trata-se de solicitação com base na Lei de Ac...      c1\n",
       "5996   Trata-se de uma solicitação repetida. As info...      c5\n",
       "5997                                           Unidade:      c5\n",
       "5998   Vale dizer que a gestão dos Telefones de Uso ...    c234\n",
       "5999   WILHAN DONIZETE GONçALVES NUNES, neste NUP 23...    c234\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino_dataset = pd.read_excel('data/ep1_esic2023_clareza_TRAIN.xlsx')\n",
    "treino_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5626</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Prezado(a) Senhor(a),  Sua manifestação foi a...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>41</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                resp_text clarity\n",
       "count                                                6000    6000\n",
       "unique                                               5626       3\n",
       "top      Prezado(a) Senhor(a),  Sua manifestação foi a...      c5\n",
       "freq                                                   41    2000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clarity\n",
       "c5      2000\n",
       "c234    2000\n",
       "c1      2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = treino_dataset['clarity'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_text</th>\n",
       "      <th>clarity</th>\n",
       "      <th>resp_text_lematizada</th>\n",
       "      <th>resp_text_stemming</th>\n",
       "      <th>resp_text_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prezado Sr Jose Taunai  Em atenção ao seu pe...</td>\n",
       "      <td>c5</td>\n",
       "      <td>Prezado Sr Jose Taunai em atenção a o seu pedi...</td>\n",
       "      <td>prez sr jos taun em atenç ao seu ped de acess ...</td>\n",
       "      <td>Prezado Sr Jose Taunai Em atenção pedido acess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A pedido do Pró-Reitor de Graduação, informa...</td>\n",
       "      <td>c5</td>\n",
       "      <td>a pedido de o Pró-Reitor de Graduação informar...</td>\n",
       "      <td>\"a ped do pró-rei de graduação, inform que a u...</td>\n",
       "      <td>\"A pedido Pró-Reitor Graduação, informamos UFS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos o contato e...</td>\n",
       "      <td>c234</td>\n",
       "      <td>Prezado o sr. o Agradecemos o contato e inform...</td>\n",
       "      <td>\"prez (a) sr. (a), agradec o contat e inform q...</td>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos contato info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos o contato e...</td>\n",
       "      <td>c234</td>\n",
       "      <td>Prezado o sr. o Agradecemos o contato e inform...</td>\n",
       "      <td>\"prez (a) sr. (a), agradec o contat e inform q...</td>\n",
       "      <td>\"Prezado (a) Sr. (a), Agradecemos contato info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Prezado Prof. Gilberto Tadeu Reis da Silva  ...</td>\n",
       "      <td>c234</td>\n",
       "      <td>Prezado Prof Gilberto Tadeu Reis de o Silva em...</td>\n",
       "      <td>\"prez prof. gilbert tad reil da silv em atend ...</td>\n",
       "      <td>\"Prezado Prof. Gilberto Tadeu Reis Silva Em at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>Trata-se de solicitação com base na Lei de Ac...</td>\n",
       "      <td>c1</td>\n",
       "      <td>tratar se de solicitação com base em o Lei de ...</td>\n",
       "      <td>trata-s de solicit com bas na lei de acess à i...</td>\n",
       "      <td>Trata-se solicitação base Lei Acesso Informaçã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Trata-se de uma solicitação repetida. As info...</td>\n",
       "      <td>c5</td>\n",
       "      <td>tratar se de um solicitação repetir o informaç...</td>\n",
       "      <td>trata-s de uma solicit repetida. as inform req...</td>\n",
       "      <td>Trata-se solicitação repetida. As informações ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Unidade:</td>\n",
       "      <td>c5</td>\n",
       "      <td>Unidade</td>\n",
       "      <td>unidade:</td>\n",
       "      <td>Unidade:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Vale dizer que a gestão dos Telefones de Uso ...</td>\n",
       "      <td>c234</td>\n",
       "      <td>Vale dizer que o gestão de o Telefones de Uso ...</td>\n",
       "      <td>val diz que a gest do telefon de uso públic é ...</td>\n",
       "      <td>Vale dizer gestão Telefones Uso Público feita ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>WILHAN DONIZETE GONçALVES NUNES, neste NUP 23...</td>\n",
       "      <td>c234</td>\n",
       "      <td>WILHAN DONIZETE GONçALVES NUNES em este NUP 23...</td>\n",
       "      <td>wilhan donizet gonçalv nunes, nest nup 2348001...</td>\n",
       "      <td>WILHAN DONIZETE GONçALVES NUNES, neste NUP 234...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resp_text clarity  \\\n",
       "0       Prezado Sr Jose Taunai  Em atenção ao seu pe...      c5   \n",
       "1      \"A pedido do Pró-Reitor de Graduação, informa...      c5   \n",
       "2      \"Prezado (a) Sr. (a), Agradecemos o contato e...    c234   \n",
       "3      \"Prezado (a) Sr. (a), Agradecemos o contato e...    c234   \n",
       "4      \"Prezado Prof. Gilberto Tadeu Reis da Silva  ...    c234   \n",
       "...                                                 ...     ...   \n",
       "5995   Trata-se de solicitação com base na Lei de Ac...      c1   \n",
       "5996   Trata-se de uma solicitação repetida. As info...      c5   \n",
       "5997                                           Unidade:      c5   \n",
       "5998   Vale dizer que a gestão dos Telefones de Uso ...    c234   \n",
       "5999   WILHAN DONIZETE GONçALVES NUNES, neste NUP 23...    c234   \n",
       "\n",
       "                                   resp_text_lematizada  \\\n",
       "0     Prezado Sr Jose Taunai em atenção a o seu pedi...   \n",
       "1     a pedido de o Pró-Reitor de Graduação informar...   \n",
       "2     Prezado o sr. o Agradecemos o contato e inform...   \n",
       "3     Prezado o sr. o Agradecemos o contato e inform...   \n",
       "4     Prezado Prof Gilberto Tadeu Reis de o Silva em...   \n",
       "...                                                 ...   \n",
       "5995  tratar se de solicitação com base em o Lei de ...   \n",
       "5996  tratar se de um solicitação repetir o informaç...   \n",
       "5997                                            Unidade   \n",
       "5998  Vale dizer que o gestão de o Telefones de Uso ...   \n",
       "5999  WILHAN DONIZETE GONçALVES NUNES em este NUP 23...   \n",
       "\n",
       "                                     resp_text_stemming  \\\n",
       "0     prez sr jos taun em atenç ao seu ped de acess ...   \n",
       "1     \"a ped do pró-rei de graduação, inform que a u...   \n",
       "2     \"prez (a) sr. (a), agradec o contat e inform q...   \n",
       "3     \"prez (a) sr. (a), agradec o contat e inform q...   \n",
       "4     \"prez prof. gilbert tad reil da silv em atend ...   \n",
       "...                                                 ...   \n",
       "5995  trata-s de solicit com bas na lei de acess à i...   \n",
       "5996  trata-s de uma solicit repetida. as inform req...   \n",
       "5997                                           unidade:   \n",
       "5998  val diz que a gest do telefon de uso públic é ...   \n",
       "5999  wilhan donizet gonçalv nunes, nest nup 2348001...   \n",
       "\n",
       "                                    resp_text_stopwords  \n",
       "0     Prezado Sr Jose Taunai Em atenção pedido acess...  \n",
       "1     \"A pedido Pró-Reitor Graduação, informamos UFS...  \n",
       "2     \"Prezado (a) Sr. (a), Agradecemos contato info...  \n",
       "3     \"Prezado (a) Sr. (a), Agradecemos contato info...  \n",
       "4     \"Prezado Prof. Gilberto Tadeu Reis Silva Em at...  \n",
       "...                                                 ...  \n",
       "5995  Trata-se solicitação base Lei Acesso Informaçã...  \n",
       "5996  Trata-se solicitação repetida. As informações ...  \n",
       "5997                                           Unidade:  \n",
       "5998  Vale dizer gestão Telefones Uso Público feita ...  \n",
       "5999  WILHAN DONIZETE GONçALVES NUNES, neste NUP 234...  \n",
       "\n",
       "[6000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aplica_lematizacao(treino_dataset, 'resp_text')\n",
    "aplica_stemming(treino_dataset, 'resp_text')\n",
    "remove_stopwords(treino_dataset, 'resp_text')\n",
    "\n",
    "treino_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression | sem pré-processamento | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l1, solver=liblinear\n",
      "Mean Accuracy: 0.3321666666666666\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l1, solver=saga\n",
      "Mean Accuracy: 0.387\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l2, solver=lbfgs\n",
      "Mean Accuracy: 0.45\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l2, solver=liblinear\n",
      "Mean Accuracy: 0.4521666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l2, solver=newton-cg\n",
      "Mean Accuracy: 0.45\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l2, solver=newton-cholesky\n",
      "Mean Accuracy: 0.44783333333333336\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l2, solver=sag\n",
      "Mean Accuracy: 0.45166666666666666\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=balanced, penalty=l2, solver=saga\n",
      "Mean Accuracy: 0.4568333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l1, solver=liblinear\n",
      "Mean Accuracy: 0.3321666666666666\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l1, solver=saga\n",
      "Mean Accuracy: 0.387\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l2, solver=lbfgs\n",
      "Mean Accuracy: 0.45\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l2, solver=liblinear\n",
      "Mean Accuracy: 0.4521666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l2, solver=newton-cg\n",
      "Mean Accuracy: 0.45\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l2, solver=newton-cholesky\n",
      "Mean Accuracy: 0.4481666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l2, solver=sag\n",
      "Mean Accuracy: 0.45166666666666666\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.001, class_weight=None, penalty=l2, solver=saga\n",
      "Mean Accuracy: 0.4568333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l1, solver=liblinear\n",
      "Mean Accuracy: 0.4171666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l1, solver=saga\n",
      "Mean Accuracy: 0.417\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l2, solver=lbfgs\n",
      "Mean Accuracy: 0.4703333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l2, solver=liblinear\n",
      "Mean Accuracy: 0.4668333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l2, solver=newton-cg\n",
      "Mean Accuracy: 0.4703333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l2, solver=newton-cholesky\n",
      "Mean Accuracy: 0.4676666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l2, solver=sag\n",
      "Mean Accuracy: 0.4686666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=balanced, penalty=l2, solver=saga\n",
      "Mean Accuracy: 0.4683333333333334\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l1, solver=liblinear\n",
      "Mean Accuracy: 0.4171666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l1, solver=saga\n",
      "Mean Accuracy: 0.417\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l2, solver=lbfgs\n",
      "Mean Accuracy: 0.4703333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l2, solver=liblinear\n",
      "Mean Accuracy: 0.4668333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l2, solver=newton-cg\n",
      "Mean Accuracy: 0.4703333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l2, solver=newton-cholesky\n",
      "Mean Accuracy: 0.46766666666666656\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l2, solver=sag\n",
      "Mean Accuracy: 0.4686666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.01, class_weight=None, penalty=l2, solver=saga\n",
      "Mean Accuracy: 0.4683333333333334\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l1, solver=liblinear\n",
      "Mean Accuracy: 0.4408333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l1, solver=saga\n",
      "Mean Accuracy: 0.44333333333333336\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l2, solver=lbfgs\n",
      "Mean Accuracy: 0.4788333333333334\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l2, solver=liblinear\n",
      "Mean Accuracy: 0.47800000000000004\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l2, solver=newton-cg\n",
      "Mean Accuracy: 0.4788333333333334\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l2, solver=newton-cholesky\n",
      "Mean Accuracy: 0.47733333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l2, solver=sag\n",
      "Mean Accuracy: 0.4786666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=balanced, penalty=l2, solver=saga\n",
      "Mean Accuracy: 0.4795\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l1, solver=liblinear\n",
      "Mean Accuracy: 0.4408333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l1, solver=saga\n",
      "Mean Accuracy: 0.44333333333333336\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l2, solver=lbfgs\n",
      "Mean Accuracy: 0.4788333333333334\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l2, solver=liblinear\n",
      "Mean Accuracy: 0.47800000000000004\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l2, solver=newton-cg\n",
      "Mean Accuracy: 0.4788333333333334\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l2, solver=newton-cholesky\n",
      "Mean Accuracy: 0.47750000000000004\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l2, solver=sag\n",
      "Mean Accuracy: 0.4786666666666667\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.1, class_weight=None, penalty=l2, solver=saga\n",
      "Mean Accuracy: 0.4795\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Hyperparameters: lowercase=True, analyzer=word, ngram_range=(1, 1), C=0.5, class_weight=balanced, penalty=l1, solver=liblinear\n",
      "Mean Accuracy: 0.4653333333333333\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n",
      "Combination skipped\n",
      "\n",
      "X_count shape: (6000, 28710)\n"
     ]
    }
   ],
   "source": [
    "X = treino_dataset.resp_text\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "lowercase_list = [True, False]\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n",
    "C_list = [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "class_weight_list = ['balanced', None]\n",
    "penalty_list = ['l1', 'l2']\n",
    "solver_list = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for lowercase, analyzer, ngram_range, C, class_weight, penalty, solver in itertools.product(lowercase_list, analyzer_list, ngram_range_list, C_list, class_weight_list, penalty_list, solver_list):\n",
    "    vectorizer = CountVectorizer(analyzer=analyzer, lowercase=lowercase, ngram_range=ngram_range)\n",
    "    X_count = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=9999, C=C, class_weight=class_weight, penalty=penalty, solver=solver, random_state=100)\n",
    "\n",
    "    accuracy = 0\n",
    "    try:\n",
    "        accuracy = cross_val_score(clf, X_count, Y, scoring='accuracy', cv=10, error_score='raise').mean()\n",
    "\n",
    "        print(f\"Hyperparameters: lowercase={lowercase}, analyzer={analyzer}, ngram_range={ngram_range}, C={C}, class_weight={class_weight}, penalty={penalty}, solver={solver}\")\n",
    "        print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = {\n",
    "                'lowercase': lowercase,\n",
    "                'analyzer': analyzer,\n",
    "                'ngram_range': ngram_range,\n",
    "                'C': C,\n",
    "                'class_weight': class_weight,\n",
    "                'penalty': penalty,\n",
    "                'solver': solver\n",
    "            }\n",
    "    except:\n",
    "        print('Combination skipped\\n')\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "lowercase_list = [True, False]\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(2, 2), (3, 3), (4, 4), (5, 5)]\n",
    "C_list = np.geomspace(3.0, 5.0, num=20)\n",
    "class_weight_list = ['balanced', None]\n",
    "penalty_list = ['l1', 'l2']\n",
    "solver_list = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for lowercase, analyzer, ngram_range, C, class_weight, penalty, solver in itertools.product(lowercase_list, analyzer_list, ngram_range_list, C_list, class_weight_list, penalty_list, solver_list):\n",
    "    vectorizer = TfidfVectorizer(analyzer=analyzer, lowercase=lowercase, ngram_range=ngram_range)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=9999, C=C, class_weight=class_weight, penalty=penalty, solver=solver, random_state=100)\n",
    "\n",
    "    accuracy = 0\n",
    "    try:\n",
    "        accuracy = cross_val_score(clf, X_tfidf, Y, scoring='accuracy', cv=10, error_score='raise').mean()\n",
    "\n",
    "        print(f\"Hyperparameters: lowercase={lowercase}, analyzer={analyzer}, ngram_range={ngram_range}, C={C}, class_weight={class_weight}, penalty={penalty}, solver={solver}\")\n",
    "        print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = {\n",
    "                'lowercase': lowercase,\n",
    "                'analyzer': analyzer,\n",
    "                'ngram_range': ngram_range,\n",
    "                'C': C,\n",
    "                'class_weight': class_weight,\n",
    "                'penalty': penalty,\n",
    "                'solver': solver\n",
    "            }\n",
    "    except:\n",
    "        print('Combination skipped\\n')\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Naive Bayes | sem pré-processamento | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2), (3, 3), (5, 5)]\n",
    "alpha_list = np.geomspace(1e-3, 1, num=50)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for analyzer, ngram_range, alpha in itertools.product(analyzer_list, ngram_range_list, alpha_list):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "    X_count = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    accuracy = cross_val_score(clf, X_count, Y, scoring='accuracy', cv=10).mean()\n",
    "\n",
    "    print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}, alpha={alpha}\")\n",
    "    print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {\n",
    "            'ngram_range': ngram_range,\n",
    "            'analyzer': analyzer,\n",
    "            'alpha': alpha\n",
    "        }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Naive Bayes | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2), (3, 3), (5, 5)]\n",
    "alpha_list = np.geomspace(1e-3, 1000, num=100)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for analyzer, ngram_range, alpha in itertools.product(analyzer_list, ngram_range_list, alpha_list):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    accuracy = cross_val_score(clf, X_tfidf, Y, scoring='accuracy', cv=10).mean()\n",
    "\n",
    "    print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}, alpha={alpha}\")\n",
    "    print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {\n",
    "            'ngram_range': ngram_range,\n",
    "            'analyzer': analyzer,\n",
    "            'alpha': alpha\n",
    "        }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Random Forest | Lematização | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer = 'word'\n",
    "ngram_range = (1, 1)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "X_count = vectorizer.fit_transform(X)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=100)\n",
    "\n",
    "accuracy = cross_val_score(clf, X, Y, scoring='accuracy', cv=10, n_jobs=3).mean()\n",
    "\n",
    "print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}\")\n",
    "print(f\"Mean Accuracy: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Random Forest | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "analyzer_list = ['word', 'char']\n",
    "ngram_range_list = [(1, 1), (2, 2)]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for analyzer, ngram_range in itertools.product(analyzer_list, ngram_range_list):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, analyzer=analyzer)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=100)\n",
    "\n",
    "    accuracy = cross_val_score(clf, X, Y, scoring='accuracy', cv=10).mean()\n",
    "\n",
    "    print(f\"Hyperparameters: ngram_range={ngram_range}, analyzer={analyzer}\")\n",
    "    print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {\n",
    "            'ngram_range': ngram_range,\n",
    "            'analyzer': analyzer,\n",
    "        }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. SVC | Lematização | Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. SVC | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. SGD Classifier | Lematização | TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination skipped\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = treino_dataset.resp_text\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "alpha_list = np.geomspace(6.632895500464648e-05, 0.00014590812272681345, num=30)\n",
    "max_iter_list = [100, 1000]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for alpha, max_iter in itertools.product(alpha_list, max_iter_list):\n",
    "    vectorizer = TfidfVectorizer(max_features=None, ngram_range=(3, 3), analyzer='char', lowercase=True)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=alpha, random_state=100, max_iter=max_iter, tol=None)\n",
    "    try:\n",
    "        accuracy = cross_val_score(clf, X_tfidf, Y, scoring='accuracy', cv=10, n_jobs=4).mean()\n",
    "\n",
    "        print(f\"Hyperparameters: alpha={alpha}, max_iter={max_iter}\")\n",
    "        print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = {\n",
    "                'alpha': alpha,\n",
    "                'max_iter': max_iter\n",
    "            }\n",
    "    except:\n",
    "        print('Combination skipped\\n')\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. SGD Classifier | Lematização | TF-IDF Vectorizer | SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=100, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49883333333333324\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=100, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.4998333333333333\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=100, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49066666666666664\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=100, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5006666666666667\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=100, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.472\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=100, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.472\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=1000, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.5018333333333334\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=1000, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5015000000000001\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=1000, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4916666666666667\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=1000, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5008333333333332\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=1000, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4680000000000001\n",
      "\n",
      "Hyperparameters: alpha=6.632895500464648e-05, max_iter=1000, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.4680000000000001\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=100, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49883333333333335\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=100, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5003333333333333\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=100, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49083333333333334\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=100, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5005000000000001\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=100, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.472\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=100, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.472\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=1000, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.5015\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=1000, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5008333333333334\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=1000, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4903333333333334\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=1000, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5013333333333334\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=1000, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.46799999999999997\n",
      "\n",
      "Hyperparameters: alpha=6.815680676459815e-05, max_iter=1000, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.46799999999999997\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=100, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49833333333333335\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=100, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5006666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=100, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49016666666666675\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=100, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5001666666666666\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=100, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4711666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=100, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.4711666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=1000, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.502\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=1000, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5011666666666666\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=1000, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49049999999999994\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=1000, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5011666666666666\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=1000, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4671666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.003502931745805e-05, max_iter=1000, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.4671666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=100, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49766666666666676\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=100, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5003333333333334\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=100, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4906666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=100, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5001666666666666\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=100, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4716666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=100, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.4716666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=1000, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.5015\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=1000, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5008333333333334\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=1000, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4893333333333333\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=1000, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5006666666666667\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=1000, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.46699999999999997\n",
      "\n",
      "Hyperparameters: alpha=7.196501074995937e-05, max_iter=1000, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.46699999999999997\n",
      "\n",
      "Hyperparameters: alpha=7.394817740085927e-05, max_iter=100, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.49766666666666676\n",
      "\n",
      "Hyperparameters: alpha=7.394817740085927e-05, max_iter=100, percentile=50, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.5\n",
      "\n",
      "Hyperparameters: alpha=7.394817740085927e-05, max_iter=100, percentile=75, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.491\n",
      "\n",
      "Hyperparameters: alpha=7.394817740085927e-05, max_iter=100, percentile=75, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.4995\n",
      "\n",
      "Hyperparameters: alpha=7.394817740085927e-05, max_iter=100, percentile=100, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.4723333333333334\n",
      "\n",
      "Hyperparameters: alpha=7.394817740085927e-05, max_iter=100, percentile=100, score_func=<function f_classif at 0x0000020DA3774550>\n",
      "Mean Accuracy: 0.4723333333333334\n",
      "\n",
      "Hyperparameters: alpha=7.394817740085927e-05, max_iter=1000, percentile=50, score_func=<function chi2 at 0x0000020DA3774700>\n",
      "Mean Accuracy: 0.5013333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = treino_dataset.resp_text\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "alpha_list = np.geomspace(6.632895500464648e-05, 0.00014590812272681345, num=30)\n",
    "max_iter_list = [100, 1000]\n",
    "percentile_list = [50, 75, 100]\n",
    "score_func_list = [chi2, f_classif]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for alpha, max_iter, percentile, score_func in itertools.product(alpha_list, max_iter_list, percentile_list, score_func_list):\n",
    "  vectorizer = TfidfVectorizer(max_features=None, ngram_range=(3, 3), analyzer='char', lowercase=True)\n",
    "  X_tfidf = vectorizer.fit_transform(X)\n",
    "  X_BestFeatures = SelectPercentile(score_func=score_func , percentile=percentile).fit_transform(X_tfidf, Y)\n",
    "\n",
    "  clf = SGDClassifier(loss='log_loss', penalty='l2', alpha=alpha, random_state=100, max_iter=max_iter, tol=None)\n",
    "  try:\n",
    "    accuracy = cross_val_score(clf, X_BestFeatures, Y, scoring='accuracy', cv=10, n_jobs=4).mean()\n",
    "\n",
    "    print(f\"Hyperparameters: alpha={alpha}, max_iter={max_iter}, percentile={percentile}, score_func={score_func}\")\n",
    "    print(f\"Mean Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {\n",
    "            'alpha': alpha,\n",
    "            'max_iter': max_iter,\n",
    "            'percentile': percentile,\n",
    "            'score_func': score_func\n",
    "        }\n",
    "  except:\n",
    "      print('Combination skipped\\n')  \n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Mean Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Tfidf shape: (6000, 24782)\n",
      "X_Best shape: (6000, 5000)\n",
      "TFIDF: 0.4623333333333333\n",
      "X_Best: 0.505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X = treino_dataset.resp_text_lematizada\n",
    "Y = treino_dataset.clarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "print(f\"X_Tfidf shape: {X_tfidf.shape}\")\n",
    "\n",
    "X_Best = SelectKBest(score_func=chi2, k=5000).fit_transform(X_tfidf, Y)\n",
    "print(f\"X_Best shape: {X_Best.shape}\")\n",
    "\n",
    "clf = LogisticRegression(max_iter=9999)\n",
    "\n",
    "accuracy = cross_val_score(clf, X_tfidf, Y, scoring='accuracy', cv=10, error_score='raise').mean()\n",
    "print(f\"TFIDF: {accuracy}\")\n",
    "accuracy = cross_val_score(clf, X_Best, Y, scoring='accuracy', cv=10, error_score='raise').mean()\n",
    "print(f\"X_Best: {accuracy}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
